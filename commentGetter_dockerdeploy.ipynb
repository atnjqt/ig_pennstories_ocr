{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selenium Web Scraping for IG Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurations for Docker container deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to repo decker deploy script\n",
    "deploy_script_path = './deploy.sh' # <-- Make sure to edit for your docker mount -v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IG Username (`username` in ig_df)\n",
    "input_wwe_username = 'blackivystories'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our instagram df from PhantomBuster\n",
    "ig_df = pd.read_csv('./data/blackivystories_PostsExtractor_03012021.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop through urls for BlackIvyStories IG username ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our exported Azure OCR df with text\n",
    "ocr_df = pd.read_json('./data/blackivystories_ig_ocr_expanded.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'language', 'text_angle', 'orientation', 'regions', 'filename',\n",
       "       'txt', 'ivy'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ocr_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We want to get our Penn urls... this worked in the jhub deployment. What about dartmouth for docker deployment?\n",
    "\n",
    "I am reverse extracting this from the filename... probably wasn't best strategy to start with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ivy_input_name = 'penn'\n",
    "ivy_input_name = 'dartmouth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "postid_filename = []\n",
    "ivy_ocr_pid = []\n",
    "\n",
    "for pid in ocr_df[ocr_df.ivy == ivy_input_name].filename.str[:-4]:\n",
    "    ivy_ocr_pid.append(int(pid))\n",
    "    \n",
    "ivy_ig_post_urls = ig_df[ig_df.postId.isin(ivy_ocr_pid)].postUrl.unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *TOTAL NUMBER OF URLS FOR IVY IG STORIES*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ivy_ig_post_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get our ids\n",
    "url_ids = []\n",
    "\n",
    "for url in ivy_ig_post_urls:\n",
    "    url_ids.append(url.split('/')[-2])\n",
    "    \n",
    "# check if they already ran (in case the cell fails)\n",
    "url_for_commentgetter = []\n",
    "\n",
    "for ig_url in url_ids:\n",
    "    json_outfile = ig_url + '.json'\n",
    "    if json_outfile not in os.listdir('./data/etl/'): # <-- the url doesn't already have a json etl outfile\n",
    "        url_for_commentgetter.append('https://www.instagram.com/p/{}/'.format(ig_url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *HOW MANY URLS ARE YOU DEPLOYING DOCKER COMMENT GETTER FOR:*\n",
    "\n",
    "*note -- If its zero then you are done for that respective ivy filter!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(url_for_commentgetter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________\n",
    "\n",
    "## DOCKER DEPLOYMENT FOR INSTAGRAM COMMENT GETTER\n",
    "\n",
    "\n",
    "- *You need Docker installed on your host... more info here: https://docs.docker.com/get-docker/*\n",
    "\n",
    "- I think Firefox is best for testing but in the past I remember using Chrome as it was more friendly in docker with selenium... we will see:\n",
    "\n",
    "_________\n",
    "\n",
    "```bash\n",
    "docker run -d -p 4444:4444 -v --shm-mem=4G selenium/standalone-firefox\n",
    "# you can rename this container\n",
    "\n",
    "# check for running container name\n",
    "docker ps\n",
    "docker rename _whatever_random_docker_name_is_ selenium-firefox\n",
    "\n",
    "# nice to have a terminal windows visible with docker stats for monitoring\n",
    "docker stats\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________\n",
    "#### *RUN FOR FIRST BUILD, OR JUST RESTART*\n",
    "\n",
    "- give it a minute to startup..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!docker run -d -p 4444:4444 -v --shm-mem=4G selenium/standalone-chrome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selenium-firefox\r\n"
     ]
    }
   ],
   "source": [
    "!docker restart selenium-firefox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID   IMAGE                         COMMAND                  CREATED             STATUS         PORTS                    NAMES\r\n",
      "35faafb3499e   selenium/standalone-firefox   \"/opt/bin/entry_poinâ€¦\"   About an hour ago   Up 3 minutes   0.0.0.0:4444->4444/tcp   selenium-firefox\r\n"
     ]
    }
   ],
   "source": [
    "!docker ps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going to scale up for the remaining 540~ URLS for the rest of ivy schools...\n",
    "\n",
    "pushing to github first as it'll run overnight ...\n",
    "__________\n",
    "\n",
    "### Docker bash deploy worked for the 16 dartmouth URLs in testing\n",
    "\n",
    "### Looping through the 55 penn story instagram URLs for comment web scraping ... \n",
    "\n",
    "Network errors seem to mess this up... maybe the restart on failure flag isn't helpful? The pipeline failed to stop a restarted container...\n",
    "\n",
    "- I removed `--restart=on-failure` from [deploy.sh](./deploy.sh)... I think if a container fails we can just rerun by refreshing urls for comment getter in cells above:\n",
    "\n",
    "- there was a runaway container which hit 150+ clicks very quickly. I think I set a threshold of 500 clicks and it stops, I just hit the stop button to stop that container though. I probably need to rerun for just that one URL? I bumped this down to 100\n",
    "- not sure why but the following URL keeps running off & clicking for the following https://www.instagram.com/p/CBn-zFWjDIf/... it did get comments and export to json though"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting comments for IG post --> https://www.instagram.com/p/CBn-zFWjDIf\n",
      "Error response from daemon: No such container: commentGetter\n",
      "Error: No such container: commentGetter\n",
      "Sending build context to Docker daemon  85.46MB\n",
      "Step 1/6 : FROM python:3.8-slim\n",
      " ---> 62297c9f4e5c\n",
      "Step 2/6 : COPY GetComments.py /app/GetComments.py\n",
      " ---> Using cache\n",
      " ---> 90c9796babd0\n",
      "Step 3/6 : COPY configs /app/configs\n",
      " ---> Using cache\n",
      " ---> abc6089367f5\n",
      "Step 4/6 : WORKDIR /app\n",
      " ---> Using cache\n",
      " ---> d8792d16e028\n",
      "Step 5/6 : RUN pip install -r /app/configs/requirements.txt\n",
      " ---> Using cache\n",
      " ---> 53541ed81935\n",
      "Step 6/6 : CMD [\"python3\", \"GetComments.py\", \"https://www.instagram.com/p/CBn-zFWjDIf\"]\n",
      " ---> Using cache\n",
      " ---> 0f5462a4c283\n",
      "Successfully built 0f5462a4c283\n",
      "Successfully tagged instagram_commentgetter:latest\n",
      "------------------------------------------------------------\n",
      "Raw html outfile prepared as: /data/raw/CBn-zFWjDIf.html\n",
      "ETL outfile prepared as: /data/etl/CBn-zFWjDIf.json\n",
      "Trying to click & load more comments --> 0\n",
      "Trying to click & load more comments --> 1\n",
      "Trying to click & load more comments --> 2\n",
      "Trying to click & load more comments --> 3\n",
      "Trying to click & load more comments --> 4\n",
      "Trying to click & load more comments --> 5\n",
      "Trying to click & load more comments --> 6\n",
      "Trying to click & load more comments --> 7\n",
      "Trying to click & load more comments --> 8\n",
      "Trying to click & load more comments --> 9\n",
      "Trying to click & load more comments --> 10\n",
      "Trying to click & load more comments --> 11\n",
      "Trying to click & load more comments --> 12\n",
      "Trying to click & load more comments --> 13\n",
      "Trying to click & load more comments --> 14\n",
      "Trying to click & load more comments --> 15\n",
      "Trying to click & load more comments --> 16\n",
      "Trying to click & load more comments --> 17\n",
      "Trying to click & load more comments --> 18\n",
      "Trying to click & load more comments --> 19\n",
      "Trying to click & load more comments --> 20\n",
      "Trying to click & load more comments --> 21\n",
      "Trying to click & load more comments --> 22\n",
      "Trying to click & load more comments --> 23\n",
      "Trying to click & load more comments --> 24\n",
      "Trying to click & load more comments --> 25\n",
      "Trying to click & load more comments --> 26\n",
      "Trying to click & load more comments --> 27\n",
      "Trying to click & load more comments --> 28\n",
      "Trying to click & load more comments --> 29\n",
      "Trying to click & load more comments --> 30\n",
      "Trying to click & load more comments --> 31\n",
      "Trying to click & load more comments --> 32\n",
      "Trying to click & load more comments --> 33\n",
      "Trying to click & load more comments --> 34\n",
      "Trying to click & load more comments --> 35\n",
      "Trying to click & load more comments --> 36\n",
      "Trying to click & load more comments --> 37\n",
      "Trying to click & load more comments --> 38\n",
      "Trying to click & load more comments --> 39\n",
      "Trying to click & load more comments --> 40\n",
      "Trying to click & load more comments --> 41\n",
      "Trying to click & load more comments --> 42\n",
      "Trying to click & load more comments --> 43\n",
      "Trying to click & load more comments --> 44\n",
      "Trying to click & load more comments --> 45\n",
      "Trying to click & load more comments --> 46\n",
      "Trying to click & load more comments --> 47\n",
      "Trying to click & load more comments --> 48\n",
      "Trying to click & load more comments --> 49\n",
      "Trying to click & load more comments --> 50\n",
      "Trying to click & load more comments --> 51\n",
      "Trying to click & load more comments --> 52\n",
      "Trying to click & load more comments --> 53\n",
      "Trying to click & load more comments --> 54\n",
      "Trying to click & load more comments --> 55\n",
      "Trying to click & load more comments --> 56\n",
      "Trying to click & load more comments --> 57\n",
      "Trying to click & load more comments --> 58\n",
      "Trying to click & load more comments --> 59\n",
      "Trying to click & load more comments --> 60\n",
      "Trying to click & load more comments --> 61\n",
      "Trying to click & load more comments --> 62\n",
      "Trying to click & load more comments --> 63\n",
      "Trying to click & load more comments --> 64\n",
      "Trying to click & load more comments --> 65\n",
      "Trying to click & load more comments --> 66\n",
      "Trying to click & load more comments --> 67\n",
      "Trying to click & load more comments --> 68\n",
      "Trying to click & load more comments --> 69\n",
      "Trying to click & load more comments --> 70\n",
      "Trying to click & load more comments --> 71\n",
      "Trying to click & load more comments --> 72\n",
      "Trying to click & load more comments --> 73\n",
      "Trying to click & load more comments --> 74\n",
      "Trying to click & load more comments --> 75\n",
      "Trying to click & load more comments --> 76\n",
      "Trying to click & load more comments --> 77\n",
      "Trying to click & load more comments --> 78\n",
      "Trying to click & load more comments --> 79\n",
      "Trying to click & load more comments --> 80\n",
      "Trying to click & load more comments --> 81\n",
      "Trying to click & load more comments --> 82\n",
      "Trying to click & load more comments --> 83\n",
      "Trying to click & load more comments --> 84\n",
      "Trying to click & load more comments --> 85\n",
      "Trying to click & load more comments --> 86\n",
      "Trying to click & load more comments --> 87\n",
      "Trying to click & load more comments --> 88\n",
      "Trying to click & load more comments --> 89\n",
      "Trying to click & load more comments --> 90\n",
      "Trying to click & load more comments --> 91\n",
      "Trying to click & load more comments --> 92\n",
      "Trying to click & load more comments --> 93\n",
      "Trying to click & load more comments --> 94\n",
      "Trying to click & load more comments --> 95\n",
      "Trying to click & load more comments --> 96\n",
      "Trying to click & load more comments --> 97\n",
      "Trying to click & load more comments --> 98\n",
      "Trying to click & load more comments --> 99\n",
      "Trying to click & load more comments --> 100\n",
      "oops! clicked 100 times apparently... not sure why this is happening so exiting this container to continue onward!\n",
      "Exporting to .html file --> /data/raw/CBn-zFWjDIf.html\n",
      "Done! Number of comments extracted --> 15\n",
      "Exporting ETL json file --> /data/etl/CBn-zFWjDIf.json\n",
      "Complete!\n",
      "---------------------------------------------------------------------------\n",
      "commentGetter\n"
     ]
    }
   ],
   "source": [
    "for url in url_for_commentgetter:\n",
    "  \n",
    "    ##################################################################\n",
    "    # Clean up URL (in case lacking https or has trailing slash)...\n",
    "    if not url.startswith('https://'):\n",
    "        url = 'https://' + url\n",
    "    if url.endswith('/'):\n",
    "        url=url[:-1]\n",
    "    \n",
    "    ##################################################################\n",
    "    # Prepare Dockerfile (using template to overwrite for next URL)\n",
    "    dockerfile_in = open(\"./configs/dockerfile_template\", \"rt\")\n",
    "    dockerfile_out = open(\"./Dockerfile\", \"wt\")\n",
    "    \n",
    "    # Replace the value w/ URL -- this loops through lines, would be better using regex...\n",
    "    for line in dockerfile_in:\n",
    "        # This is how url gets passed to container...\n",
    "        dockerfile_out.write(line.replace('replace_with_url', '\"{}\"'.format(url)))\n",
    "    \n",
    "    #close input and output dockerfile & template\n",
    "    dockerfile_in.close()\n",
    "    dockerfile_out.close()\n",
    "    \n",
    "    ##################################################################\n",
    "    # BEGIN LOOPING THROUGH URLS BY LAUNCHING DOCKER CommentGetters\n",
    "    print('Getting comments for IG post --> {}'.format(url))\n",
    "    try:\n",
    "        !bash $deploy_script_path\n",
    "    except:\n",
    "        print('oops! failed for {}'.format(url))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID   IMAGE                            COMMAND                  CREATED              STATUS              PORTS                    NAMES\r\n",
      "cf28a2d6f945   instagram_commentgetter:latest   \"python3 GetCommentsâ€¦\"   About a minute ago   Up About a minute                            commentGetter\r\n",
      "35faafb3499e   selenium/standalone-firefox      \"/opt/bin/entry_poinâ€¦\"   About an hour ago    Up 9 minutes        0.0.0.0:4444->4444/tcp   selenium-firefox\r\n"
     ]
    }
   ],
   "source": [
    "!docker ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "etl_files = [item for item in os.listdir('./data/etl/') if item.endswith('.json')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for getting url fron image filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "etl_files = [item for item in os.listdir('./data/etl/') if item.endswith('.json')]\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for etl in etl_files:\n",
    "    dfs.append(pd.read_json('./data/etl/{}'.format(etl)))\n",
    "    \n",
    "etl_df = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1109, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etl_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>author</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.instagram.com/p/CB1vWGmJJWc</td>\n",
       "      <td>blackivystories</td>\n",
       "      <td>@uofpenn . . . . . . #blackstudentsmatter   #b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.instagram.com/p/CB1vWGmJJWc</td>\n",
       "      <td>doreenm1</td>\n",
       "      <td>ðŸ˜¡  @uofpenn   @columbia  enough of this racist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.instagram.com/p/CB1vWGmJJWc</td>\n",
       "      <td>jay_theorist</td>\n",
       "      <td>@skaijackson 36w Reply</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.instagram.com/p/CB1vWGmJJWc</td>\n",
       "      <td>View</td>\n",
       "      <td>replies (1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.instagram.com/p/CB1vWGmJJWc</td>\n",
       "      <td>janzibrown</td>\n",
       "      <td>Wow 36w 1 like Reply</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>https://www.instagram.com/p/CCl0jqGh0S1</td>\n",
       "      <td>View</td>\n",
       "      <td>replies (1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>https://www.instagram.com/p/CCl0jqGh0S1</td>\n",
       "      <td>victoriatellez</td>\n",
       "      <td>What the fuck 33w 1 like Reply</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>https://www.instagram.com/p/CCl0jqGh0S1</td>\n",
       "      <td>kiwikiwikiwi25</td>\n",
       "      <td>ðŸ˜ž What an ignorant and horrible thing to say. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>https://www.instagram.com/p/CCl0jqGh0S1</td>\n",
       "      <td>catie.mc23</td>\n",
       "      <td>@dartmouthcollege 33w Reply</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>https://www.instagram.com/p/CCl0jqGh0S1</td>\n",
       "      <td>grace.chennn</td>\n",
       "      <td>Eww  @isabwu_19 28w Reply</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1109 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        url           author  \\\n",
       "0   https://www.instagram.com/p/CB1vWGmJJWc  blackivystories   \n",
       "1   https://www.instagram.com/p/CB1vWGmJJWc         doreenm1   \n",
       "2   https://www.instagram.com/p/CB1vWGmJJWc     jay_theorist   \n",
       "3   https://www.instagram.com/p/CB1vWGmJJWc             View   \n",
       "4   https://www.instagram.com/p/CB1vWGmJJWc       janzibrown   \n",
       "..                                      ...              ...   \n",
       "24  https://www.instagram.com/p/CCl0jqGh0S1             View   \n",
       "25  https://www.instagram.com/p/CCl0jqGh0S1   victoriatellez   \n",
       "26  https://www.instagram.com/p/CCl0jqGh0S1   kiwikiwikiwi25   \n",
       "27  https://www.instagram.com/p/CCl0jqGh0S1       catie.mc23   \n",
       "28  https://www.instagram.com/p/CCl0jqGh0S1     grace.chennn   \n",
       "\n",
       "                                              comment  \n",
       "0   @uofpenn . . . . . . #blackstudentsmatter   #b...  \n",
       "1   ðŸ˜¡  @uofpenn   @columbia  enough of this racist...  \n",
       "2                              @skaijackson 36w Reply  \n",
       "3                                         replies (1)  \n",
       "4                                Wow 36w 1 like Reply  \n",
       "..                                                ...  \n",
       "24                                        replies (1)  \n",
       "25                     What the fuck 33w 1 like Reply  \n",
       "26  ðŸ˜ž What an ignorant and horrible thing to say. ...  \n",
       "27                        @dartmouthcollege 33w Reply  \n",
       "28                          Eww  @isabwu_19 28w Reply  \n",
       "\n",
       "[1109 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etl_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
